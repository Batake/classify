{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1528957054455,
     "user": {
      "displayName": "Wataru Takabatake",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112859107402282445541"
     },
     "user_tz": -540
    },
    "id": "X6R7YDnA8O0K",
    "outputId": "7eb99653-fe1f-4967-afc3-8ec269910856"
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "%matplotlib inline\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import sys\n",
    "import shutil\n",
    "import traceback\n",
    "import itertools\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import wave\n",
    "import time as tm\n",
    "import scipy.fftpack\n",
    "from pylab import *\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def notify_finishing(is_silent=True):\n",
    "    if is_silent:\n",
    "        title = '\"report\"'\n",
    "        content = '\"Finish\"'\n",
    "        cmd = \"osascript -e 'display notification \" + content +  \" with title \" + title + \"'\"\n",
    "        os.system(cmd)\n",
    "    else:\n",
    "        cmd = \"say Finish\"\n",
    "        os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##情報が欲しい距離のインデックスを取得\n",
    "def d_index_set(d, index_num, width):\n",
    "    dmin_index = []\n",
    "    dmax_index = []\n",
    "    for n in range(index_num):\n",
    "        dmin_index.append(len(d[d < n * 0.8 - width]))\n",
    "        dmax_index.append(len(d[d< n * 0.8 + width]))\n",
    "    return dmin_index, dmax_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hUg783jF8O0O"
   },
   "outputs": [],
   "source": [
    "#パラメータ設定\n",
    "Fs = 1/ (8 * (pow(10, (-6)))) #サンプリング周波数\n",
    "Tc = 1024*(10**(-6))#掃引時間\n",
    "B = 187.4 * pow(10, 6) #掃引帯域幅\n",
    "c = 3 * pow(10, 8) #光速\n",
    "integral_range = 0.3 #距離のプラマイの積分範囲\n",
    "Sa = 4096 #大体(データ数 / 測定時間)　\n",
    "\n",
    "data_length = 102400\n",
    "time_sum = 12.5\n",
    "window = 128\n",
    "overlap = 128\n",
    "NFFT = pow(2, 16)\n",
    "M = math.ceil((data_length - window)/overlap) - 1\n",
    "win_func = hanning(M)\n",
    "delta_f = Fs / NFFT\n",
    "xaxis = delta_f * np.arange(NFFT)\n",
    "tau = xaxis * Tc / B #Tc:B = tau:ビート周波数(xaxisに対応)\n",
    "d = c * tau / 2 #距離推定\n",
    "\n",
    "dmin_index, dmax_index = d_index_set(d, index_num = 6, width= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "BDZnBKSu8O0S"
   },
   "outputs": [],
   "source": [
    "class FileOperation:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def merge_csv(name, temp_dir, orginal_dir ):\n",
    "    \"\"\"a_1.txt, a_2.txt, a_3.txtのようなファイルを結合\"\"\"\n",
    "        file_index = 1\n",
    "\n",
    "        '''original_dirをtarget_dirにコピーしてそこの中で重複をなくす作業を行う'''\n",
    "        target_dir = original_dir.rsplit('/', 1)[0] + '/' + temp_dir\n",
    "        if os.path.exists(target_dir):\n",
    "            shutil.rmtree(target_dir)\n",
    "        shutil.copytree(original_dir, target_dir)\n",
    "\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                files = sorted(glob.glob(target_dir + '/' + name + '_*[a-z][1-9].txt'))# 1ケタついてる用\n",
    "            elif i == 1:\n",
    "                files = sorted(glob.glob(target_dir + '/' + name + '_*[a-z][1-9][0-9].txt'))# 2ケタついてる用\n",
    "\n",
    "            for file in files:\n",
    "                file_name = file.split('.')[0]\n",
    "                file_name_short = file.rsplit('/', 1)[1].split('.')[0]\n",
    "                print(file_name)\n",
    "                same_files = sorted(glob.glob(file_name + '_' + '*' + '.txt'))\n",
    "                if len(same_files) > 0:\n",
    "                    for same_file in same_files:\n",
    "                        csv1 = pd.read_csv(file_name + '.txt', delimiter=\"   \", header=None, skiprows=7, engine='python').iloc[:, 0:3]\n",
    "                        csv2 = pd.read_csv(same_file, delimiter=\"   \", header=None, engine='python', skipfooter=1).iloc[:, 0:3]\n",
    "                        csv_concat = pd.concat([csv1, csv2], ignore_index=True)\n",
    "                        np.savetxt(file_name + '.txt', csv_concat, fmt=[\"%1.0d\", \"%0.3f\", \"%0.3f\"], delimiter=\"   \")\n",
    "                        os.remove(same_file)\n",
    "    \n",
    "    ##不必要なファイルの除外\n",
    "    def set_file_excluded(files, exclude_actions):\n",
    "        file_excluded = []\n",
    "        for i, file in enumerate(files):\n",
    "            action = file.rsplit('/', 1)[1].split('.')[0].split('_')[1][:-1]\n",
    "            if action not in exclude_actions:\n",
    "                file_excluded.append(file)\n",
    "        return file_excluded\n",
    "    \n",
    "    ##不必要な行動変化の時間データの除外\n",
    "    def set_source_excluded(source, exclude_actions):\n",
    "        for i, action in enumerate(exclude_actions):\n",
    "            source = source[(source[\"act\"] != action)]\n",
    "        source_excluded = source.reset_index(drop=True)\n",
    "        return source_excluded\n",
    "        \n",
    "    def get_action(file):\n",
    "        action = file.rsplit('/', 1)[1].split('.')[0].split('_')[1]\n",
    "        return action\n",
    "    \n",
    "    def get_subject(file):\n",
    "        subject = file.rsplit('/', 2)[1]\n",
    "        return subject\n",
    "            \n",
    "    def label_from_action(action):\n",
    "        if action == \"fall\" or action == \"standfall\":\n",
    "            label = [1]\n",
    "        elif action == \"front\":\n",
    "            label = [2]\n",
    "        elif action == \"side\":\n",
    "            label = [3]\n",
    "        elif action == \"back\":\n",
    "            label = [4]\n",
    "        elif action == \"bodychange\" or action == \"other\":\n",
    "            label = [5]\n",
    "        elif action == \"sit\":\n",
    "            label = [6]\n",
    "        elif action == \"stand\":\n",
    "            label = [7]\n",
    "        else:\n",
    "            label = [0]\n",
    "            print(\"Anything is wrong.\")\n",
    "        return label\n",
    "    \n",
    "    \n",
    "    ##ラベル付けしたデータの保存\n",
    "    def save_labeled_data(feature_with_label, savefolder, subject, action, source_index):\n",
    "        if source_index < 10:\n",
    "            source_index_str = \"00\" + str(source_index)\n",
    "        elif source_index < 100:\n",
    "            source_index_str= \"0\" + str(source_index)\n",
    "        else:\n",
    "            source_index_str = str(source_index)\n",
    "        save_name = savefolder + subject + '_' + action +'_' + source_index_str + '.csv'\n",
    "        np.savetxt(save_name, feature_with_label, delimiter=',')\n",
    "        #csvのデータ数が１なら削除\n",
    "        if os.path.getsize(save_name) == 1:\n",
    "            os.remove(save_name)\n",
    "    \n",
    "    def merge_files(self, data_folder, save_folder):\n",
    "        files = []\n",
    "        files = sorted(glob.glob(data_folder))\n",
    "        files_excluded = self.set_file_excluded(files, exclude_actions)\n",
    "        for i, file in enumerate(files_excluded):\n",
    "            action = get_action(file)\n",
    "            subject = get_subject(file)\n",
    "\n",
    "            doppler = self.doppler_from_IQdata(file)\n",
    "            data_length = len(doppler)\n",
    "            time_sum = data_length / Sa\n",
    "\n",
    "            cdf = CalculateDistanceFeatures(doppler)\n",
    "            spec = cdf.__spec_tdp_from_doppler()\n",
    "            distance = cdf.__max_distance_from_spec(Spec)\n",
    "            distance_reshaped = np.reshape(np.array(distance), ( len(distance), 1))\n",
    "\n",
    "            if int(i / 100) >= 1:\n",
    "                number = str(i)\n",
    "            elif int(i / 10) >= 1:    \n",
    "                number = \"0\"+str(i)\n",
    "            else:\n",
    "                number = \"00\"+str(i)\n",
    "            with open(savefolder + subject + \"_\" + action + \"_\" + number  + '.csv', 'w') as csv_file:\n",
    "                for index, content in enumerate(distance_reshaped):\n",
    "                    writer = csv.writer(csv_file)\n",
    "                    writer.writerow(content)                    \n",
    "                    \n",
    "    def sql_operation(self, data_path):\n",
    "        import sqlite3\n",
    "        from contextlib import closing\n",
    "        files = []\n",
    "        files = sorted(glob.glob(data_path))\n",
    "        exclude_actions = ['no']\n",
    "        files_excluded = set_file_excluded(files, exclude_actions)\n",
    "\n",
    "        dbname = 'experiment.db'\n",
    "        with closing(sqlite3.connect(dbname)) as conn:\n",
    "            c = conn.cursor()\n",
    "            drop_table = '''drop table if exists subjects'''\n",
    "            conn.execute(drop_table)\n",
    "\n",
    "        #         executeメソッドでSQL文を実行する\n",
    "            create_table = '''create table subjects (id int primary key, name varchar(64), action varchar(64), start int, end int, std_after float, mean_after float, range_after float, grav_posi float, diff_sum float, std float, mean float, max float, min float, range float, mean_diff float, time float, label integer)'''    \n",
    "            c.execute(create_table)\n",
    "            for i, file in enumerate(files_excluded):\n",
    "                name = file.rsplit(\".\")[0].rsplit(\"_\")[5].split(\"/\")[1]\n",
    "                action = file.rsplit(\".\")[0].rsplit(\"_\")[6]\n",
    "\n",
    "            #カラムの追加\n",
    "        #         add_column=\"alter table　subjects add column label integer;\"\n",
    "        #         add_column=\"ALTER TABLE subjects ADD COLUMN label integer\"\n",
    "        #         c.execute(add_column)\n",
    "            # 受注表(csv)を開く。\n",
    "                with open(file, 'r') as f: \n",
    "                    b = csv.reader(f)\n",
    "                    header = next(b)\n",
    "                    subject = tuple([name, action])\n",
    "                    subject = tuple(tuple([str(i)]) + subject +  tuple(header))\n",
    "        #             # tableに各行のデータを挿入する。\n",
    "                    print(subject)\n",
    "        # #                 cur.execute('INSERT INTO subjects　(id int primary key, std_after float, mean_after float, range_after float, grav_posi float, diff_sum float, std float, mean float, max float, min float, range float, mean_diff float, time float) values (?,?,?,?,?,?,?,?,?,?,?,?,?);', t)　\n",
    "                    sql = 'insert into subjects (id, name, action, std_after, mean_after, range_after, grav_posi, diff_sum, std, mean, max, min, range, mean_diff, time, label) values (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)'\n",
    "        #             sql = 'insert into subjects (name, action) values (?, ?)'\n",
    "        #             sql = \"UPDATE subjects SET name=name WHERE name='None'\"\n",
    "        #             sql = \"replace into subjects(id, name, action) values(?, ?, ?);\"\n",
    "                    c.execute(sql, subject)\n",
    "            conn.commit()\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MakeLabelFile:\n",
    "    def __init__(self, data_per_second, st_threshold, boundary, sec_start, sec_end, time_interval, convolve_range, observe_time):\n",
    "        self.data_per_second = data_per_second\n",
    "        self.st_threshold = st_threshold\n",
    "        self.boundary = boundary\n",
    "        self.sec_start = sec_start#秒後から見る\n",
    "        self.sec_end = sec_end #秒前まで見る\n",
    "        self.starts, self.ends, self.numbers, self.actions, self.states = [], [], [], [], []\n",
    "        self.time_interval = time_interval\n",
    "        self.convolve_box = np.ones(convolve_range)/convolve_range\n",
    "        self.observe_time = observe_time\n",
    "\n",
    "\n",
    "    def __judge_label(self, std_start, std_end):\n",
    "        if std_start < self.label_start:\n",
    "            start_detected = self.label_start\n",
    "        elif self.label_start <= std_start and std_start <= self.label_end:\n",
    "            start_detected = std_start\n",
    "        else:\n",
    "            start_detected = self.label_end\n",
    "\n",
    "        if std_end < self.label_start:\n",
    "            end_detected = self.label_start\n",
    "        elif self.label_start <= std_end and std_end <= self.label_end:\n",
    "            end_detected = std_end\n",
    "        else:\n",
    "            end_detected = self.label_end    \n",
    "\n",
    "        if (end_detected - start_detected)/(self.label_end - self.label_start) >= self.boundary:\n",
    "            label = FileOperation.label_from_action(self.action)#actionにより1~7のlabelを返す\n",
    "        else:\n",
    "            label = [8]\n",
    "\n",
    "        return label\n",
    "\n",
    "\n",
    "    def __extend_datas(self):\n",
    "        start_flag, end_flag = 0, 0\n",
    "        called_flag = 0\n",
    "        data_interval = int(self.data_per_second * self.time_interval)\n",
    "        for data_i in range(self.data_per_second*self.sec_start, len(self.distance) - self.data_per_second * self.sec_end, data_interval):\n",
    "            if np.std(self.distance[data_i:data_i+data_interval]) >self.st_threshold:\n",
    "                if start_flag == 0:\n",
    "                    start_flag = 1\n",
    "                    self.starts.extend([data_i/self.data_per_second])\n",
    "                    self.numbers.extend([self.file_index])\n",
    "                    self.actions.append(self.action)\n",
    "                    if (called_flag == 1) and (self.starts[-1] - self.ends[-1] < self.observe_time):\n",
    "                        del self.starts[-2], self.numbers[-2], self.actions[-2], self.ends[-1], self.states[-1]\n",
    "            else:\n",
    "                if start_flag == 1:\n",
    "                    start_flag = 0\n",
    "                    called_flag = 1\n",
    "                    self.ends.extend([data_i/self.data_per_second])\n",
    "                    label = self.__judge_label(std_start = self.starts[-1], std_end = self.ends[-1])\n",
    "                    self.states.append(label)\n",
    "\n",
    "        if len(self.ends) != len(self.starts):\n",
    "            self.ends.extend([data_i/self.data_per_second])\n",
    "            label = self.__judge_label(std_start = self.starts[-1], std_end = self.ends[-1])\n",
    "            self.states.append(label)\n",
    "        \n",
    "        \n",
    "    def make_label_file(self, data_folder, time_file, exclude_actions, save_file):\n",
    "        files = []\n",
    "        files = sorted(glob.glob(data_folder))\n",
    "        source = pd.read_csv(time_file, delimiter=',', encoding='cp932', engine='python')\n",
    "        files_excluded = FileOperation.set_file_excluded(files, exclude_actions)\n",
    "        source_excluded = FileOperation.set_source_excluded(source, exclude_actions)\n",
    "        labels_start, labels_end = source_excluded[\"change_start_s\"], source_excluded[\"change_end_s\"]\n",
    "        \n",
    "        for file_index, file in enumerate(files_excluded):\n",
    "            self.file_index = file_index\n",
    "            self.action = FileOperation.get_action(file)[:-1]\n",
    "            self.distance_original = pd.read_csv(file, skiprows= 0, header=None, names=['distance'], engine='python')['distance']\n",
    "            self.distance = np.convolve(self.distance_original, self.convolve_box, 'same')\n",
    "            self.label_start, self.label_end = labels_start[file_index], labels_end[file_index]\n",
    "            self.__extend_datas()\n",
    "            \n",
    "#         all_action = reduce(lambda x,y: x+y, self.actions)\n",
    "        data_extended = pd.DataFrame({\"number\":self.numbers, \"change_start_s\":self.starts, \"change_end_s\":self.ends, \"state\":self.states, \"act\": self.actions})\n",
    "        data_extended.to_csv(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MakeFeaturesFile:\n",
    "    def __init__(self, see_after_time, see_before_time, time_diff, t_observe, t_division):\n",
    "        self.see_after_time=see_after_time\n",
    "        self.see_before_time=see_before_time\n",
    "        self.time_diff = time_diff\n",
    "        self.t_observe = t_observe\n",
    "        self.t_division = t_division\n",
    "        \n",
    "    def _doppler_from_IQdata(self, file):\n",
    "        # 空の配列にIQ信号を入れる．要素がないところには0を入れる\n",
    "        try:\n",
    "            temp = pd.read_csv(file, delimiter=\"   \", skiprows= 0, header=None, names=['No.', 'I','Q'], engine='python')\n",
    "            zero = np.zeros((temp.shape[0], 2), dtype=np.int64)\n",
    "            data_length = temp.shape[0]\n",
    "            IQdata = pd.DataFrame(zero, columns=['I','Q'])\n",
    "            IQdata.I = temp.I\n",
    "            IQdata.Q = temp.Q\n",
    "            doppler = IQdata.I+1j* IQdata.Q\n",
    "        except:\n",
    "            temp = pd.read_csv(file, delimiter=\"   \", skiprows= 7, header=None, names=['No.', 'I','Q'], engine='python')\n",
    "            zero = np.zeros((temp.shape[0], 2), dtype=np.int64)\n",
    "            data_length = temp.shape[0]\n",
    "            IQdata = pd.DataFrame(zero, columns=['I','Q'])\n",
    "            IQdata.I = temp.I\n",
    "            IQdata.Q = temp.Q\n",
    "            doppler = IQdata.I+1j* IQdata.Q\n",
    "\n",
    "        self.data_length = len(doppler)\n",
    "        self.time_sum = self.data_length / Sa\n",
    "        self.feature_bin = int(self.time_sum * Sa / overlap) #Specのnp.shapeと少しずれあり\n",
    "        return doppler\n",
    "    \n",
    "    #time, distance, powerのspectrogram\n",
    "    def _spec_tdp_from_doppler(self, doppler):\n",
    "        self.M = math.ceil((self.data_length-window)/overlap)  - 1\n",
    "#         new_x = zeros(window + (self.M + 1) * window, dtype = complex64)\n",
    "        new_x = zeros(window + (self.M + 1) * overlap, dtype = complex64)\n",
    "        new_x[: self.data_length] = doppler # 信号をいい感じの長さにする\n",
    "        Spec = zeros([self.M, NFFT], dtype = complex64) # スペクトログラムの初期化(複素数型)\n",
    "        win_func = hanning(window)\n",
    "        #STFTをする\n",
    "        for m in range(self.M):\n",
    "            start = overlap * m\n",
    "            Spec[m, :] = abs(fft(new_x[start : start + window] * win_func, NFFT))**2\n",
    "        Spec = abs(Spec)\n",
    "        \n",
    "        Spec_in_drange = Spec[0:, dmin_index[0]:dmax_index[3]]\n",
    "        return Spec_in_drange\n",
    "    \n",
    "    def _spec_bg_cut(self, Spec, Spec_bg):\n",
    "        spec_len = np.shape(Spec)[0]\n",
    "        spec_bg_len = np.shape(Spec_bg)[0]\n",
    "        if spec_len <= spec_bg_len:\n",
    "            Spec_bg = Spec_bg[0:spec_len, :]\n",
    "        else:\n",
    "            Spec_bg = np.concatenate([Spec_bg, Spec_bg[0:spec_len-spec_bg_len, :]], axis=0)\n",
    "        \n",
    "        Spec_bg_cut = abs(Spec - Spec_bg)\n",
    "        return Spec_bg_cut\n",
    "    \n",
    "    def _max_distance_from_spec(self, Spec):\n",
    "        distance = d[np.argmax(Spec, axis=1)]\n",
    "        return distance\n",
    "    \n",
    "    def _gra_med_from_spec(self, Spec, label_start, label_end):\n",
    "        spec_len = np.shape(Spec)[0]\n",
    "        change_startframe = int(label_start*spec_len/ self.time_sum)\n",
    "        change_endframe = int(label_end*spec_len/ self.time_sum)\n",
    "        gra_med = [np.sum(d[dmin_index[0]:dmax_index[3]] * np.sum(abs(Spec[change_startframe:change_endframe, dmin_index[0]:dmax_index[3]]), axis=0))/np.sum(abs(Spec[change_startframe:change_endframe, dmin_index[0]:dmax_index[3]]))]    \n",
    "        return gra_med\n",
    "    \n",
    "    def _create_features_labeled(self, Spec, distance, label, label_start, label_end):\n",
    "        gra_med = self._gra_med_from_spec(Spec, label_start, label_end)\n",
    "        #距離の特徴量にSpecから取ったpowerの時系列から特徴量取得して連結\n",
    "        max_power = np.max(Spec, axis=1)\n",
    "        features_with_label = self._feature_from_distance(distance, label_start,  label_end, [label], gra_med)\n",
    "        min_power = np.min(Spec, axis=1)\n",
    "        mean_power = np.mean(Spec, axis=1)\n",
    "        std_power = np.std(Spec, axis=1)\n",
    "        \n",
    "        min_distance = d[np.argmin(Spec, axis=1)]\n",
    "        features_of_min_distance = self._feature_from_distance(min_distance, label_start,  label_end, [label], gra_med)\n",
    "        \n",
    "        features_of_max_power = self._feature_from_distance(max_power, label_start,  label_end, [label], gra_med)\n",
    "        features_of_min_power = self._feature_from_distance(min_power, label_start,  label_end, [label], gra_med)\n",
    "        features_of_mean_power = self._feature_from_distance(mean_power, label_start,  label_end, [label], gra_med)\n",
    "        features_of_std_power = self._feature_from_distance(std_power, label_start,  label_end, [label], gra_med)\n",
    "        \n",
    "        features_with_label = np.concatenate([features_with_label[0][:-1], features_of_min_distance[0][:-1], features_of_max_power[0][:-1], features_of_min_power[0][:-1], features_of_mean_power[0][:-1], features_of_std_power[0]])\n",
    "        features_with_label = np.array(features_with_label).reshape(1, len(features_with_label))#形整えた\n",
    "        return features_with_label\n",
    "    \n",
    "    def _create_features_distance(self, Spec, distance, label, label_start, label_end):\n",
    "        gra_med = self._gra_med_from_spec(Spec, label_start, label_end)\n",
    "        features_with_label = self._feature_from_distance(distance, label_start,  label_end, [label], gra_med)\n",
    "        features_with_label = np.array([features_with_label[0][1], features_with_label[0][-1]])\n",
    "        features_with_label = np.array(features_with_label).reshape(1, len(features_with_label))#形整えた\n",
    "        return features_with_label\n",
    "        \n",
    "    def _create_features_grad_std(self, Spec, label, label_start, label_end):\n",
    "        gra_med = self._gra_med_from_spec(Spec, label_start, label_end)\n",
    "        std_power = np.std(abs(Spec), axis=1)\n",
    "        mean_std_power = np.mean(std_power)\n",
    "        features_with_label = np.array([round(gra_med[0], 3), mean_std_power, label])\n",
    "        features_with_label = np.array(features_with_label).reshape(1, len(features_with_label))#形整えた\n",
    "        return features_with_label\n",
    "        \n",
    "    def make_distance_file(self, data_folder, exclude_actions, save_folder):\n",
    "        files = sorted(glob.glob(data_folder))\n",
    "        files_excluded = FileOperation.set_file_excluded(files, exclude_actions)\n",
    "        \n",
    "        for file_index, file in enumerate(files_excluded):        \n",
    "            doppler = self. _doppler_from_IQdata(file)\n",
    "            Spec = self._spec_tdp_from_doppler(doppler)\n",
    "            distance = self._max_distance_from_spec(Spec)\n",
    "            action, subject = FileOperation.get_action(file), FileOperation.get_subject(file)\n",
    "            FileOperation.save_labeled_data(distance, save_folder, subject, action, file_index)\n",
    "    \n",
    "    def _feature_from_distance(self, distance, label_start, label_end, label, gra_med):\n",
    "        change_startframe = int(label_start*len(distance)/ self.time_sum)\n",
    "        change_endframe = int(label_end*len(distance)/ self.time_sum)\n",
    "        \n",
    "        time_after = self.see_after_time \n",
    "        after_frame =  int(self.see_after_time*len(distance)/ self.time_sum)\n",
    "    \n",
    "        dist_after = distance[change_endframe:change_endframe+after_frame]\n",
    "        dist_middle = distance[change_startframe:change_endframe+1]\n",
    "    \n",
    "        std_after = [np.std(dist_after)] #-3. 変化終了後の距離の標準偏差\n",
    "        mean_after = [np.mean(dist_after)] #-2. 変化終了後の距離平均\n",
    "        gra_med = gra_med  #3. 重心の位置\n",
    "        d_diff = zeros(change_endframe - change_startframe, dtype=float64)\n",
    "        d_diff[:len(dist_middle)-1] = np.diff(dist_middle, n=1)\n",
    "        sum_abs_dist = [np.sum(list(map(lambda x: abs(x), d_diff)))] #4. 前後の距離の差の絶対値の合計\n",
    "        diff_std = [np.std(d_diff)] #4.3 前後の差の準偏偏差\n",
    "#             features.extend([np.sum(np.diff(distance[j], n=2))]) #4.6前後の差の差の和\n",
    "        \n",
    "        _diff_jump = int(self.time_diff*27)\n",
    "        diff_broad_mean = [np.mean(dist_middle[-1:0:-_diff_jump])]\n",
    "        diff_broad_std = [np.std(dist_middle[-1:0:-_diff_jump])]\n",
    "        \n",
    "        #t_divisionずつで区切った場合のベクトル\n",
    "        _div_std = []\n",
    "        _div_mean = []       \n",
    "        for i in range(int(self.t_observe/self.t_division)*2-1):\n",
    "            div_distance = distance[change_endframe-int((i*0.5)*27*self.t_division):change_endframe-int((i*0.5+1)*27*self.t_division):-1]\n",
    "            _div_std.append(np.std(div_distance))\n",
    "            _div_mean.append(np.mean(div_distance))\n",
    "        div_feature = np.concatenate([_div_std, _div_mean])\n",
    "        \n",
    "        dis_std = [np.std(dist_middle)] #5. 距離の標準偏差\n",
    "        dis_mean = [np.mean(dist_middle)] #6. 距離の平均値\n",
    "        dis_max = [np.max(dist_middle)] #8. 距離の最大値\n",
    "        dis_min = [np.min(dist_middle)]#9. 距離の最小値\n",
    "        diff_max_min = [dis_max[0] - dis_min[0]]#10. 距離の最大値と最小値の差\n",
    "        diff_mean = [dis_mean[0] - mean_after[0]]#11. 行動後の平均距離 -  行動中の平均距離\n",
    "        action_time = [label_end - label_start]#12. 行動時間\n",
    "    \n",
    "        features_with_label = []\n",
    "        features_with_label.extend(np.concatenate([std_after, mean_after, gra_med, sum_abs_dist, diff_std, diff_broad_mean, diff_broad_std, div_feature, dis_std, dis_mean, dis_max, diff_max_min, diff_mean, action_time, label]))\n",
    "        features_with_label_reshaped = np.array(features_with_label).reshape(1, len(features_with_label))\n",
    "        return features_with_label_reshaped\n",
    "\n",
    "    def make_features_files(self, data_folder, time_file, exclude_actions, save_folder, method, should_bg_cut):\n",
    "        files = sorted(glob.glob(data_folder))\n",
    "        files_excluded = FileOperation.set_file_excluded(files, exclude_actions)\n",
    "        source = pd.read_csv(time_file, delimiter=',', encoding='cp932', engine='python')\n",
    "        source_excluded = FileOperation.set_source_excluded(source, exclude_actions)\n",
    "        labels_start, labels_end, numbers, labels = source_excluded[\"change_start_s\"], source_excluded[\"change_end_s\"], source_excluded[\"number\"], source_excluded[\"state\"]\n",
    "        source_index = 0\n",
    "        doppler_bg = self. _doppler_from_IQdata(bg_path)\n",
    "        Spec_bg = self._spec_tdp_from_doppler(doppler_bg)\n",
    "        \n",
    "        for file_index, file in enumerate(files_excluded):\n",
    "            doppler = self. _doppler_from_IQdata(file)\n",
    "            Spec = self._spec_tdp_from_doppler(doppler)\n",
    "            if should_bg_cut:\n",
    "                Spec_bg_cut = self._spec_bg_cut(Spec, Spec_bg)\n",
    "            else:\n",
    "                Spec_bg_cut = Spec\n",
    "            distance = self._max_distance_from_spec(Spec_bg_cut) #従来法では必要なので残す\n",
    "            action, subject = FileOperation.get_action(file), FileOperation.get_subject(file)\n",
    "            \n",
    "            while source_index < len(numbers) and numbers[source_index] == file_index:\n",
    "                label_start, label_end = labels_start[source_index], labels_end[source_index]\n",
    "                if label_end - label_start < 0 or label_start > self.time_sum :\n",
    "                    source_index = source_index+1\n",
    "                    continue\n",
    "                label = float(labels[source_index][1])\n",
    "\n",
    "                if method == \"propose\":\n",
    "                    features_with_label = self._create_features_labeled(Spec, distance, label, label_start, label_end)\n",
    "                elif method == \"conv_dist\":\n",
    "                    features_with_label = self._create_features_distance(Spec_bg_cut, distance, label, label_start, label_end)\n",
    "                elif method == \"conv_grad_std\":\n",
    "                    features_with_label = self._create_features_grad_std(Spec_bg_cut, label, label_start, label_end)\n",
    "                FileOperation.save_labeled_data(features_with_label, save_folder, subject, action, source_index)\n",
    "\n",
    "                source_index = source_index+1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Attach_Label_Both_2.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
