{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "%matplotlib inline\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import sys\n",
    "import traceback\n",
    "import itertools\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import wave\n",
    "import time as tm\n",
    "import scipy.fftpack\n",
    "from pylab import *\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_labeled_data(csv_path, two_class)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import collections\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "#データ準備\",\n",
    "print(csv_path)\n",
    "csv_files = sorted(glob.glob(csv_path))\n",
    "data_list = []\n",
    "\n",
    "for f in csv_files:\n",
    "    data_list.append(pd.read_csv(f, header=None))\n",
    "distance = pd.concat(data_list)\n",
    "\n",
    "distance = distance.fillna(0)\n",
    "X = distance.iloc[:, 0:shape(distance)[1]-1]\n",
    "Y = distance.iloc[:, shape(distance)[1] - 1].astype(np.int64)\n",
    "\n",
    "# #ダウンサンプリング前before\",\n",
    "print(\"before\")\n",
    "count_dict = collections.Counter(Y)\n",
    "print(count_dict)\n",
    "\n",
    "if two_class:\n",
    "    Y[Y<=4] = 1\n",
    "    Y[Y>=5] = 0\n",
    "    # # 負例をダウンサンプリング\\n\",\n",
    "    rus = RandomUnderSampler(random_state=1)\n",
    "    # # 学習用データに反映\\n\",\n",
    "    X, Y = rus.fit_sample(X, Y)\n",
    "    #ダウンサンプリング後\\n\",\n",
    "    \n",
    "else:\n",
    "    X = X[Y != 8]\n",
    "    Y = Y[Y != 8][0]\n",
    "    \n",
    "# #ダウンサンプリング後after\",\n",
    "count_dict = collections.Counter(Y)\n",
    "print(count_dict)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_importances(feature_importances, feature_names, save_path):\n",
    "    #特徴量の重要度\n",
    "    feature = feature_importances\n",
    "\n",
    "#     #特徴量の重要度を上から順に出力する\n",
    "    f = pd.DataFrame({'number': range(0, len(feature)), 'feature': feature[:]})\n",
    "    f2 = f.sort_values('feature',ascending=False)\n",
    "    f3 = f2.ix[:, 'number']\n",
    "\n",
    "    #特徴量の名前\n",
    "    label = pd.DataFrame(feature_names)\n",
    "\n",
    "    #特徴量の重要度順（降順）\n",
    "    indices = feature\n",
    "    for i, indice in enumerate(indices):\n",
    "        print(str(i) + \": \" +  str(indice))\n",
    "    \n",
    "    for i in range(len(feature)):\n",
    "        print(str(i + 1) + \"   \" + str(feature_names[indices[i]]) + \"   \" + str(feature[indices[i]]))\n",
    "        \n",
    "    plt.bar(indices, feature[indices], color='red', align='center')\n",
    "    plt.xlabel(\"features\")\n",
    "    plt.ylabel(\"feature importances\")\n",
    "    plt.xlim([-1, len(feature)])\n",
    "    plt.tight_layout()\n",
    "#     plt.show()\n",
    "    plt.savefig(save_path)\n",
    "#     return indices, feature_names, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_forest():\n",
    "    tree.export_graphviz(clf, out_file=dot_data,feature_names=train_X.columns, max_depth=3)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    graph.write_pdf(\"graph.pdf\")\n",
    "    Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest(X, Y, scoring, feature_names, save_path):\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.feature_selection import RFECV\n",
    "    from sklearn import cross_validation\n",
    "    from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------\n",
    "    #2クラスor多クラス\n",
    "    #n_fold: 交差検定の回数，num_class: クラスの種類の数，scoring: スコアの種類\n",
    "    if two_class:\n",
    "        n_fold = 5\n",
    "        num_class = 2\n",
    "        scoring = scoring\n",
    "    else:\n",
    "        n_fold = 4\n",
    "        num_class = 7\n",
    "        scoring = \"accuracy\" \n",
    "    \n",
    "    print(\"n_fold = %d\" % n_fold)\n",
    "    print(\"num_class: %d\" % num_class)\n",
    "    print(\"scoring: %s\" % scoring)\n",
    "    k_fold = cross_validation.KFold(n=len(X), n_folds=n_fold, shuffle=True, random_state=0)\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------\n",
    "    print(\"feature names\")\n",
    "    print(feature_names)\n",
    "    \n",
    "#     num_trees = [10, 100]\n",
    "    num_trees = [10]\n",
    "#     max_dep = [5, 6, 7, 8,  9, 10]\n",
    "    max_dep = [9]\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------\n",
    "    #特徴量減らしていくpart1\n",
    "    for a, nt in enumerate(num_trees):\n",
    "        for b, md in enumerate(max_dep):\n",
    "            print(\"num_trees: %1.1f\" % nt)\n",
    "            print(\"max_dep: %1.1f\" % md)\n",
    "            \n",
    "            rfc = RFC(random_state=42, n_estimators=nt, max_depth=md)\n",
    "#             svm = SVC(kernel='linear', random_state=None)\n",
    "\n",
    "            skf = StratifiedKFold(n_splits=n_fold, random_state=0, shuffle=True)        \n",
    "            rfecv = RFECV(estimator=rfc, step=1, cv=skf, scoring=scoring)\n",
    "            \n",
    "            if two_class:\n",
    "                for train, test in k_fold:\n",
    "                    rfecv.fit(X[train], Y[train])\n",
    "                    y_pred = rfecv.predict(X[test])\n",
    "                    \n",
    "            else:\n",
    "                Y = np.array(Y)\n",
    "                b = np.zeros([num_class, num_class])\n",
    "                c_m = np.zeros([num_class, num_class])\n",
    "                for train, test in k_fold:\n",
    "                    rfecv.fit(X[train], Y[train])\n",
    "                    y_pred = rfecv.predict(X[test])\n",
    "                    b = confusion_matrix(Y[test], y_pred)\n",
    "#                     print(b)\n",
    "                    c_m += b\n",
    "    \n",
    "                c_m[0] = c_m[0] / 42\n",
    "                c_m[1] = c_m[1] / 34\n",
    "                c_m[2] = c_m[2] / 32\n",
    "                c_m[3] = c_m[3] / 28\n",
    "                c_m[4] = c_m[4] / 25             \n",
    "                c_m[5] = c_m[5] / 15             \n",
    "                c_m[6] = c_m[6] / 27\n",
    "                print(c_m*100)\n",
    "                np.savetxt(save_path, c_m, delimiter=',')\n",
    "            rfecv.fit(X, Y)\n",
    "            \n",
    "            print(\"features: %s\" % np.array(feature_names)[rfecv.support_])\n",
    "            print(\"importance_: %s\" % rfecv.estimator_.feature_importances_)\n",
    "            print(\"Best Score: %f\" % rfecv.grid_scores_[np.argmax(rfecv.grid_scores_)])\n",
    "            print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "            \n",
    "#             Plot number of features VS. cross-validation scores\n",
    "#             plt.figure()\n",
    "#             plt.xlabel(\"Number of features selected\")\n",
    "#             plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "#             plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "#             plt.show()\n",
    "            print(\"-----------------------------\")\n",
    "            \n",
    "            #特徴量の重要度の算出\n",
    "#             feature_importances = rfecv.estimator_.feature_importances_   \n",
    "#             show_importances(feature_importances, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# scoring = \"accuracy\"\n",
    "# scoring = \"precision\"\n",
    "# scoring = \"recall\"\n",
    "scoring = \"f1\"\n",
    "\n",
    "two_class = True\n",
    "multi_class = not two_class\n",
    "\n",
    "for i in range(1,11):\n",
    "    csv_path = any_csv_path_you_want\n",
    "    feature_names=list(np.arange(0, len(pd.DataFrame(X).columns), 1))\n",
    "    random_forest(X,Y,scoring, feature_names)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
